{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 is: \n",
      " -0.0014879539185581603\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[11.8313792  11.89818787 12.35449265 11.95761129 12.04355372 11.32055357\n 11.9511804  12.95953852 12.37370349 12.29225034 12.26904744 12.65235975\n 12.1388639  12.10625231 12.35879373 11.46163217 10.858999   12.10625231\n 13.12603064 11.38509209 11.62625415 11.8493977  12.02574909 11.88621167\n 12.25486281 11.96718074 12.26857785 11.67419361 12.13081016 11.35040654\n 11.88448902 12.45097769 11.72803684 11.81228904 12.34800614 11.60823564\n 12.35978037 11.96400108 11.86779879 11.94470788 12.09884928 11.41861479\n 12.19551713 12.23076526 11.98915964 11.91772368 12.24047407 11.87059991\n 12.54610995 12.82799232 12.36734079 12.27606502 12.46843691 11.91638857\n 11.7829526  11.87756858 12.27839331 12.07823927 11.87756858 11.9511804\n 12.5776362  12.34583459 12.5776362  12.70350903 11.86358234 12.35233515\n 11.99535161 11.79810441 12.86424011 11.6127708  12.73596533 11.3736634\n 11.97350987 12.04355372 10.91508846 11.84141593 12.04355372 12.3883942\n 11.90090526 12.57418197 11.81303006 11.8493977  12.71640215 11.89478071\n 12.77705219 11.87059991 12.49087558 11.8913619  12.01370075 11.31447453\n 12.27022047 11.27720313 11.87059991 11.77912851 12.38797745 12.08672589\n 12.47716791 12.3327053  11.9797992  12.28765263 12.92391244 11.90496755\n 12.08953883 12.00089179 12.14153412 11.98292909 12.26434155 11.84222921\n 11.58988651 11.33857208 12.05524976 11.56076279 11.64836504 11.57119437\n 12.10015642 11.53272809 12.15477935 12.7367009  12.10071213 12.23563145\n 11.78676213 11.91839057 12.13350195 11.66907415 12.61087086 12.14419724\n 11.87059991 11.8386256  12.46843691 11.68687877 12.02873863 11.35627165\n 12.25247902 12.23999086 11.62625415 12.17044547 12.19349386 11.84222921\n 11.69316152 12.19854438 11.81303006 12.31716669 12.63460303 11.7905572\n 12.03171926 12.56723749 12.19095901 11.80894766 11.80335376 12.63134038\n 12.10071213 12.35707552 12.07767093 12.08953883 12.3327053  12.01460943\n 12.31716669 12.24288662 12.45410391 12.8411298  12.32163099 12.42801548\n 11.51292546 12.98804081 12.10348606 11.70354582 11.95761129 12.10071213\n 11.58058411 12.84132585 12.1281111  12.07254125 12.18075484 12.67576373\n 12.15477935 12.12675884 11.60367983 11.76756768 11.90496755 11.97603035\n 10.5789798  11.92503512 12.09368751 11.72803684 12.34583459 11.88448902\n 11.74006104 11.97035031 12.00456827 11.76756768 12.17818744 11.75194237\n 12.33929149 12.54254488 12.36307639 12.07254125 12.17044547 11.69524702\n 12.887127   11.82700601 11.87756858 12.07539432 11.60823564 12.45254202\n 11.60823564 12.34147728 11.7352687  12.00762171 12.45683136 12.38421883\n 12.20607265 12.04941884 12.56024446 12.17303279 11.87862358 12.4292162\n 12.42118403 12.6181823  12.69465266 11.75587164 12.10071213 11.4019939\n 12.15477935 12.14950229 12.16525065 11.45899712 12.67607627 11.75978554\n 11.81303006 11.68657621 11.30220443 11.38509209 12.69158046 11.84904049\n 11.89818787 12.23076526 11.75194237 12.06681058 12.16002871 11.4019939\n 11.6351431  12.09793049 12.63101353 11.9511804  11.44035477 12.458775\n 12.53177279 12.70076889 12.01370075 11.77143616 12.229545   12.16002871\n 12.01672647 12.06104687 11.69107165 11.75587164 11.9797992  11.94405832\n 11.7745202  11.9316358  12.1281111  11.75194237 12.03469103 12.50539916\n 12.40901349 12.45293272 11.81303006 11.3736634  12.38755635 12.08099117\n 11.66134547 12.82362845 12.07823927 11.9316358  11.91772368 12.03171926\n 12.46843691 12.27373129 11.8313792  12.04060821 11.68266824 11.92768062\n 12.0662357  12.49874226 12.21849517 12.1281111  12.27792808 12.66980666\n 11.48246626 11.77528973 11.56076279 11.71993963 12.67607627 11.75194237\n 11.24504602 11.79810441 11.6784399  11.69524702 12.0981533  12.34583459\n 11.8493977  12.96219463 11.66992921 12.36734079 11.58988651 11.98292909\n 11.87756858 12.48156194 11.81303006 12.47800636 11.73606902 12.33138284\n 11.81303006 12.15477935 11.71177632 12.14153412 12.51355735 12.05815252\n 11.74006104 11.72399644 12.17498953 11.3736634  12.12323437 12.11669483\n 11.34450681 12.20607265 12.11724143 12.17303279 11.7829526  11.80559508\n 12.01672647 11.73606902 11.26446411 12.09848743 11.77528973 12.43718437\n 12.35233515 11.28978191 11.73606902 12.29910751 12.08953883 12.01974307\n 12.07823927 12.52352588 12.03112384 11.98292909 11.82041016 13.22672339\n 11.75978554 13.34550693 12.5776362  11.31447453 11.73606902 12.13618652\n 11.61728548 12.43987123 11.60823564 11.85651517 11.66134547 12.03112384\n 12.37158708 11.54829261 12.00701176 11.6351431  12.43153351 12.30138283\n 11.74403719 11.84581988 12.54254488 11.98227263 12.24673463 11.72803684\n 11.89818787 11.66992921 11.96718074 11.30220443 12.24769432 11.95761129\n 12.1281111  12.02873863 11.79433792 12.04296531 12.18841771 11.44035477\n 12.08390501 12.02873863 12.06681058 12.38421883 11.60823564 11.34450681\n 12.39669301 12.07254125 12.06681058 11.76756768 11.60732614 11.40756495\n 12.20657252 12.6230611  11.91772368 11.84222921 12.33710091 12.36734079\n 12.32385568 13.27582754 12.4049235  11.96400108 11.60823564 12.68849879\n 12.5098741  11.98292909 11.69524702 10.54270639 12.37581542 12.15477935\n 10.46024211 12.66032792 12.21849517 12.27839331 11.9316358  12.24288662\n 11.97035031 11.77528973 12.4049235  11.27720313 10.91508846 12.33710091\n 12.69349862 12.16002871 12.00150548 12.25961341 12.88029182 11.87059991\n 11.38509209 11.79810441 11.88379913 11.42409425 11.8277362  11.47729829\n 11.91170158 12.07196966 12.28534583 12.31268238 11.99380721 12.30138283\n 11.92337811 11.75978554 12.10015642 12.6181823  13.07107008 12.04355372\n 12.72188581 11.65268741 11.59910316 12.66539443 12.50617724 11.86358234\n 12.55292652 12.00762171 12.4292162  11.7191263  11.94470788 11.9511804\n 11.00209984 11.28978191 11.51292546 11.79433792 11.97665948 11.73206099\n 11.78676213 12.10071213 11.23848862 11.58988651 11.96400108 12.32385568\n 12.14419724 11.19821472 11.41861479 12.06527492 11.45635511 12.25486281\n 11.76756768 11.90496755 12.25961341 11.97665948 12.19551713 11.6784399\n 11.31447453 12.04355372 11.82407989 12.67294638 11.5228758  11.89818787\n 12.5776362  11.69107165 11.66134547 11.43927892 11.56171563 12.93675161\n 12.27839331 11.860055   11.7905572  11.59450545 11.88448902 12.00150548\n 11.8493977  11.60823564 11.79433792 12.59640043 12.20557252 11.77143616\n 12.31940133 12.87901712 12.09514108 12.12269104 12.08107616 11.49272276\n 12.03765399 11.51292546 11.90834024 11.75587164 11.69940503 11.60823564\n 11.86358234 11.01862914 12.31043266 11.58431546 12.17044547 12.19349386\n 11.6351431  12.86099861 11.90834024 11.90158345 12.11833373 12.46651198\n 12.38421883 11.85651517 11.8493977  11.89067673 12.30591798 11.62625415\n 11.72480582 12.3883942  11.66992921 12.54686767 12.52634291 11.77528973\n 12.7512997  11.71993963 12.09625778 11.85651517 11.87756858 11.75194237\n 12.17921519 12.27839331 12.67607627 11.8493977  11.73606902 12.30138283\n 12.34125892 12.01672647 11.28978191 12.90634687 12.3327053  12.2869012\n 11.58524613 11.51292546 12.17561344 11.91839057 12.34583459 12.06104687\n 12.56755103 12.22046853 11.28853113 12.99453001 11.58058411 11.87409031\n 12.05466819 11.51292546 12.10015642 11.80484853 12.3883942  11.39639165\n 11.82407989 12.36734079 11.83500896 11.86446223 12.14153412 12.11121236\n 11.8493977  11.88448902 12.07254125 12.36307639 11.60732614 11.7745202\n 11.84510278 12.5776362  11.98417831 11.84222921 11.7905572  12.01974307\n 12.00756073 11.88793137 12.20607265 11.99535161 11.69940503 11.38509209\n 11.28853113 12.32385568 12.42480649 12.38708501 12.15477935 12.03171926\n 11.79244935 11.6483301  12.4292162  11.82704253 12.85055465 11.77528973\n 12.14950229 11.73606902 12.05815252 12.35449265 11.84078933 11.51292546\n 11.77528973 12.59473064 12.00762171 12.8346813  11.65268741 11.84222921\n 12.08390501 11.84222921 12.31043266 12.02574909 12.66980666 12.26434155\n 12.06104687 11.81303006 12.39255221 12.21930965 12.74444437 11.84222921\n 12.30591798 12.64109656 12.10071213 12.14950229 12.09625778 12.08390501\n 12.21106019 11.6195352  12.09737323 11.40756495 12.39462475 12.46458334\n 11.75978554 11.36210258 11.73606902 12.51355735 11.97035031 11.98292909\n 12.24288662 11.820116   11.83101549 11.40756495 11.3736634  12.07823927\n 12.0917835  11.87583096 12.66032792 11.87756858 12.1388639  11.86358234\n 11.29601246 11.9316358  12.08390501 12.49500394 12.97154049 12.15477935\n 11.87059991 11.94145585 12.4874851  11.81303006 12.24961095 12.50432367\n 11.91170158 11.42409425 12.25486281 11.48760766 12.01370075 12.27134527\n 11.83428406 11.9511804  13.0530133  12.4073795  11.60823564 11.62625415\n 11.81154748 11.68687877 12.31492705 12.16785143 11.9381932  11.49272276\n 11.84653647 12.1388639  12.08953883 11.98292909 11.9103584  12.08390501\n 12.48582713 11.76679219 12.36788533 12.34346657 12.45293272 12.20607265\n 11.99843328 11.72803684 11.46163217 11.44035477 12.18075484 12.76568843\n 11.88448902 12.15477935 12.20607265 11.73206099 11.53272809 12.05379521\n 12.20055746 11.77528973 10.97678203 11.28978191 12.86099861 12.82772919\n 12.46071486 11.71586631 11.85651517 12.3779229  11.62625415 11.7745202\n 11.68855803 11.89818787 12.27139211 12.22587527 11.97035031 11.57590026\n 11.32659589 11.96400108 11.66992921 12.03469103 11.85082525 12.59133505\n 11.92503512 11.71177632 11.90496755 12.52088339 11.9697172  12.4292162\n 11.8493977  12.37370349 11.98292909 11.19134184 12.00150548 11.56171563\n 11.58988651 11.75587164 11.56171563 12.02574909 12.14791373 12.06104687\n 12.06968002 12.12269104 12.79135618 12.22587527 11.99535161 12.72486644\n 12.36734079 11.68266824 12.16525065 12.36734079 12.08107616 12.41105223\n 11.82041016 12.20607265 11.62625415 11.75978554 11.8277362  12.4292162\n 12.52197768 11.69940503 12.3883942  12.53537639 12.04355372 12.02718519\n 12.32829028 12.10901093 12.8583197  11.8386256  12.00150548 11.69441334\n 11.84222921 12.52452638 11.6784399  11.68687877 12.6165253  11.8313792\n 12.13618652 11.51192496 11.9511804  12.50617724 11.9511804  11.60732614\n 11.92171836 11.50791292 11.9381932  11.32055357 11.77143616 12.52441728\n 12.01612206 12.27839331 12.04941884 11.87234663 12.01370075 11.85651517\n 11.97938532 12.01066585 12.54254488 11.71177632 11.69524702 12.66270604\n 12.30138283 12.66032792 11.97035031 12.46997419 12.04941884 11.79433792\n 12.1281111  12.07823927 12.1281111  12.10625231 12.09514108 11.79433792\n 12.05815252 11.48246626 11.87687389 11.57590026 12.17818744 11.60367983\n 12.04060821 12.18841771 11.9511804  12.42250573 11.56171563 12.7512997\n 12.47418956 11.66564655 11.69940503 12.56024446 11.32659589 11.6784399\n 11.65268741 11.8493977  11.94470788 12.13269518 12.31043266 11.81303006\n 11.8493977  12.10071213 12.2067774  11.98292909 12.14153412 11.90496755\n 12.88520203 11.71177632 11.74403719 12.27839331 11.83500896 11.76756768\n 11.33260191 11.9511804  12.34583459 11.57355009 12.29910751 11.96400108\n 12.4292162  11.94470788 12.05980333 12.09514108 11.81303006 12.72783821\n 12.25486281 11.8968264  12.04355372 11.90496755 12.27373129 11.76368418\n 11.86709728 12.22096126 11.8277362  12.07539432 12.49312952 12.32341114\n 11.90496755 11.70849225 12.05233855 12.92999148 11.54248427 12.01364014\n 12.79917571 11.8493977  11.75978554 12.17561344 11.6307085  11.57119437\n 12.10348606 12.53357621 11.99535161 11.98915964 11.91371298 12.36734079\n 11.49882654 11.96356787 11.87027118 12.49874226 12.35449265 12.30817787\n 11.6127708  12.54075757 12.14685329 12.52452638 11.73606902 11.8493977\n 12.15477935 11.8493977  12.69250311 11.49577931 12.21503239 11.92503512\n 12.84397135 11.58988651 11.82407989 12.33655251 11.7905572  12.56374709\n 12.01370075 12.18586994 12.01309451 12.16525065 12.43320822 11.89818787\n 12.49117264 12.06104687 11.84510278 10.86856845 11.60823564 12.13725833\n 12.21106019 11.88448902 11.73606902 12.16525065 12.33569641 12.88567095\n 12.49125159 13.19561384 11.51292546 12.32829028 12.20856953 11.6784399\n 11.98292909 12.01066585 11.68687877 11.86709728 12.02574909 11.51292546\n 12.53537639 12.08069081 11.81303006 11.65268741 12.15451616 12.06681058].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3b435ca0017d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"R^2 is: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# predict the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m# Mean Square Error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeanSquareError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ellite/New Volume/practise/python/MLKistCollege/LinearRegression.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, X_test)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coef_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m    206\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[11.8313792  11.89818787 12.35449265 11.95761129 12.04355372 11.32055357\n 11.9511804  12.95953852 12.37370349 12.29225034 12.26904744 12.65235975\n 12.1388639  12.10625231 12.35879373 11.46163217 10.858999   12.10625231\n 13.12603064 11.38509209 11.62625415 11.8493977  12.02574909 11.88621167\n 12.25486281 11.96718074 12.26857785 11.67419361 12.13081016 11.35040654\n 11.88448902 12.45097769 11.72803684 11.81228904 12.34800614 11.60823564\n 12.35978037 11.96400108 11.86779879 11.94470788 12.09884928 11.41861479\n 12.19551713 12.23076526 11.98915964 11.91772368 12.24047407 11.87059991\n 12.54610995 12.82799232 12.36734079 12.27606502 12.46843691 11.91638857\n 11.7829526  11.87756858 12.27839331 12.07823927 11.87756858 11.9511804\n 12.5776362  12.34583459 12.5776362  12.70350903 11.86358234 12.35233515\n 11.99535161 11.79810441 12.86424011 11.6127708  12.73596533 11.3736634\n 11.97350987 12.04355372 10.91508846 11.84141593 12.04355372 12.3883942\n 11.90090526 12.57418197 11.81303006 11.8493977  12.71640215 11.89478071\n 12.77705219 11.87059991 12.49087558 11.8913619  12.01370075 11.31447453\n 12.27022047 11.27720313 11.87059991 11.77912851 12.38797745 12.08672589\n 12.47716791 12.3327053  11.9797992  12.28765263 12.92391244 11.90496755\n 12.08953883 12.00089179 12.14153412 11.98292909 12.26434155 11.84222921\n 11.58988651 11.33857208 12.05524976 11.56076279 11.64836504 11.57119437\n 12.10015642 11.53272809 12.15477935 12.7367009  12.10071213 12.23563145\n 11.78676213 11.91839057 12.13350195 11.66907415 12.61087086 12.14419724\n 11.87059991 11.8386256  12.46843691 11.68687877 12.02873863 11.35627165\n 12.25247902 12.23999086 11.62625415 12.17044547 12.19349386 11.84222921\n 11.69316152 12.19854438 11.81303006 12.31716669 12.63460303 11.7905572\n 12.03171926 12.56723749 12.19095901 11.80894766 11.80335376 12.63134038\n 12.10071213 12.35707552 12.07767093 12.08953883 12.3327053  12.01460943\n 12.31716669 12.24288662 12.45410391 12.8411298  12.32163099 12.42801548\n 11.51292546 12.98804081 12.10348606 11.70354582 11.95761129 12.10071213\n 11.58058411 12.84132585 12.1281111  12.07254125 12.18075484 12.67576373\n 12.15477935 12.12675884 11.60367983 11.76756768 11.90496755 11.97603035\n 10.5789798  11.92503512 12.09368751 11.72803684 12.34583459 11.88448902\n 11.74006104 11.97035031 12.00456827 11.76756768 12.17818744 11.75194237\n 12.33929149 12.54254488 12.36307639 12.07254125 12.17044547 11.69524702\n 12.887127   11.82700601 11.87756858 12.07539432 11.60823564 12.45254202\n 11.60823564 12.34147728 11.7352687  12.00762171 12.45683136 12.38421883\n 12.20607265 12.04941884 12.56024446 12.17303279 11.87862358 12.4292162\n 12.42118403 12.6181823  12.69465266 11.75587164 12.10071213 11.4019939\n 12.15477935 12.14950229 12.16525065 11.45899712 12.67607627 11.75978554\n 11.81303006 11.68657621 11.30220443 11.38509209 12.69158046 11.84904049\n 11.89818787 12.23076526 11.75194237 12.06681058 12.16002871 11.4019939\n 11.6351431  12.09793049 12.63101353 11.9511804  11.44035477 12.458775\n 12.53177279 12.70076889 12.01370075 11.77143616 12.229545   12.16002871\n 12.01672647 12.06104687 11.69107165 11.75587164 11.9797992  11.94405832\n 11.7745202  11.9316358  12.1281111  11.75194237 12.03469103 12.50539916\n 12.40901349 12.45293272 11.81303006 11.3736634  12.38755635 12.08099117\n 11.66134547 12.82362845 12.07823927 11.9316358  11.91772368 12.03171926\n 12.46843691 12.27373129 11.8313792  12.04060821 11.68266824 11.92768062\n 12.0662357  12.49874226 12.21849517 12.1281111  12.27792808 12.66980666\n 11.48246626 11.77528973 11.56076279 11.71993963 12.67607627 11.75194237\n 11.24504602 11.79810441 11.6784399  11.69524702 12.0981533  12.34583459\n 11.8493977  12.96219463 11.66992921 12.36734079 11.58988651 11.98292909\n 11.87756858 12.48156194 11.81303006 12.47800636 11.73606902 12.33138284\n 11.81303006 12.15477935 11.71177632 12.14153412 12.51355735 12.05815252\n 11.74006104 11.72399644 12.17498953 11.3736634  12.12323437 12.11669483\n 11.34450681 12.20607265 12.11724143 12.17303279 11.7829526  11.80559508\n 12.01672647 11.73606902 11.26446411 12.09848743 11.77528973 12.43718437\n 12.35233515 11.28978191 11.73606902 12.29910751 12.08953883 12.01974307\n 12.07823927 12.52352588 12.03112384 11.98292909 11.82041016 13.22672339\n 11.75978554 13.34550693 12.5776362  11.31447453 11.73606902 12.13618652\n 11.61728548 12.43987123 11.60823564 11.85651517 11.66134547 12.03112384\n 12.37158708 11.54829261 12.00701176 11.6351431  12.43153351 12.30138283\n 11.74403719 11.84581988 12.54254488 11.98227263 12.24673463 11.72803684\n 11.89818787 11.66992921 11.96718074 11.30220443 12.24769432 11.95761129\n 12.1281111  12.02873863 11.79433792 12.04296531 12.18841771 11.44035477\n 12.08390501 12.02873863 12.06681058 12.38421883 11.60823564 11.34450681\n 12.39669301 12.07254125 12.06681058 11.76756768 11.60732614 11.40756495\n 12.20657252 12.6230611  11.91772368 11.84222921 12.33710091 12.36734079\n 12.32385568 13.27582754 12.4049235  11.96400108 11.60823564 12.68849879\n 12.5098741  11.98292909 11.69524702 10.54270639 12.37581542 12.15477935\n 10.46024211 12.66032792 12.21849517 12.27839331 11.9316358  12.24288662\n 11.97035031 11.77528973 12.4049235  11.27720313 10.91508846 12.33710091\n 12.69349862 12.16002871 12.00150548 12.25961341 12.88029182 11.87059991\n 11.38509209 11.79810441 11.88379913 11.42409425 11.8277362  11.47729829\n 11.91170158 12.07196966 12.28534583 12.31268238 11.99380721 12.30138283\n 11.92337811 11.75978554 12.10015642 12.6181823  13.07107008 12.04355372\n 12.72188581 11.65268741 11.59910316 12.66539443 12.50617724 11.86358234\n 12.55292652 12.00762171 12.4292162  11.7191263  11.94470788 11.9511804\n 11.00209984 11.28978191 11.51292546 11.79433792 11.97665948 11.73206099\n 11.78676213 12.10071213 11.23848862 11.58988651 11.96400108 12.32385568\n 12.14419724 11.19821472 11.41861479 12.06527492 11.45635511 12.25486281\n 11.76756768 11.90496755 12.25961341 11.97665948 12.19551713 11.6784399\n 11.31447453 12.04355372 11.82407989 12.67294638 11.5228758  11.89818787\n 12.5776362  11.69107165 11.66134547 11.43927892 11.56171563 12.93675161\n 12.27839331 11.860055   11.7905572  11.59450545 11.88448902 12.00150548\n 11.8493977  11.60823564 11.79433792 12.59640043 12.20557252 11.77143616\n 12.31940133 12.87901712 12.09514108 12.12269104 12.08107616 11.49272276\n 12.03765399 11.51292546 11.90834024 11.75587164 11.69940503 11.60823564\n 11.86358234 11.01862914 12.31043266 11.58431546 12.17044547 12.19349386\n 11.6351431  12.86099861 11.90834024 11.90158345 12.11833373 12.46651198\n 12.38421883 11.85651517 11.8493977  11.89067673 12.30591798 11.62625415\n 11.72480582 12.3883942  11.66992921 12.54686767 12.52634291 11.77528973\n 12.7512997  11.71993963 12.09625778 11.85651517 11.87756858 11.75194237\n 12.17921519 12.27839331 12.67607627 11.8493977  11.73606902 12.30138283\n 12.34125892 12.01672647 11.28978191 12.90634687 12.3327053  12.2869012\n 11.58524613 11.51292546 12.17561344 11.91839057 12.34583459 12.06104687\n 12.56755103 12.22046853 11.28853113 12.99453001 11.58058411 11.87409031\n 12.05466819 11.51292546 12.10015642 11.80484853 12.3883942  11.39639165\n 11.82407989 12.36734079 11.83500896 11.86446223 12.14153412 12.11121236\n 11.8493977  11.88448902 12.07254125 12.36307639 11.60732614 11.7745202\n 11.84510278 12.5776362  11.98417831 11.84222921 11.7905572  12.01974307\n 12.00756073 11.88793137 12.20607265 11.99535161 11.69940503 11.38509209\n 11.28853113 12.32385568 12.42480649 12.38708501 12.15477935 12.03171926\n 11.79244935 11.6483301  12.4292162  11.82704253 12.85055465 11.77528973\n 12.14950229 11.73606902 12.05815252 12.35449265 11.84078933 11.51292546\n 11.77528973 12.59473064 12.00762171 12.8346813  11.65268741 11.84222921\n 12.08390501 11.84222921 12.31043266 12.02574909 12.66980666 12.26434155\n 12.06104687 11.81303006 12.39255221 12.21930965 12.74444437 11.84222921\n 12.30591798 12.64109656 12.10071213 12.14950229 12.09625778 12.08390501\n 12.21106019 11.6195352  12.09737323 11.40756495 12.39462475 12.46458334\n 11.75978554 11.36210258 11.73606902 12.51355735 11.97035031 11.98292909\n 12.24288662 11.820116   11.83101549 11.40756495 11.3736634  12.07823927\n 12.0917835  11.87583096 12.66032792 11.87756858 12.1388639  11.86358234\n 11.29601246 11.9316358  12.08390501 12.49500394 12.97154049 12.15477935\n 11.87059991 11.94145585 12.4874851  11.81303006 12.24961095 12.50432367\n 11.91170158 11.42409425 12.25486281 11.48760766 12.01370075 12.27134527\n 11.83428406 11.9511804  13.0530133  12.4073795  11.60823564 11.62625415\n 11.81154748 11.68687877 12.31492705 12.16785143 11.9381932  11.49272276\n 11.84653647 12.1388639  12.08953883 11.98292909 11.9103584  12.08390501\n 12.48582713 11.76679219 12.36788533 12.34346657 12.45293272 12.20607265\n 11.99843328 11.72803684 11.46163217 11.44035477 12.18075484 12.76568843\n 11.88448902 12.15477935 12.20607265 11.73206099 11.53272809 12.05379521\n 12.20055746 11.77528973 10.97678203 11.28978191 12.86099861 12.82772919\n 12.46071486 11.71586631 11.85651517 12.3779229  11.62625415 11.7745202\n 11.68855803 11.89818787 12.27139211 12.22587527 11.97035031 11.57590026\n 11.32659589 11.96400108 11.66992921 12.03469103 11.85082525 12.59133505\n 11.92503512 11.71177632 11.90496755 12.52088339 11.9697172  12.4292162\n 11.8493977  12.37370349 11.98292909 11.19134184 12.00150548 11.56171563\n 11.58988651 11.75587164 11.56171563 12.02574909 12.14791373 12.06104687\n 12.06968002 12.12269104 12.79135618 12.22587527 11.99535161 12.72486644\n 12.36734079 11.68266824 12.16525065 12.36734079 12.08107616 12.41105223\n 11.82041016 12.20607265 11.62625415 11.75978554 11.8277362  12.4292162\n 12.52197768 11.69940503 12.3883942  12.53537639 12.04355372 12.02718519\n 12.32829028 12.10901093 12.8583197  11.8386256  12.00150548 11.69441334\n 11.84222921 12.52452638 11.6784399  11.68687877 12.6165253  11.8313792\n 12.13618652 11.51192496 11.9511804  12.50617724 11.9511804  11.60732614\n 11.92171836 11.50791292 11.9381932  11.32055357 11.77143616 12.52441728\n 12.01612206 12.27839331 12.04941884 11.87234663 12.01370075 11.85651517\n 11.97938532 12.01066585 12.54254488 11.71177632 11.69524702 12.66270604\n 12.30138283 12.66032792 11.97035031 12.46997419 12.04941884 11.79433792\n 12.1281111  12.07823927 12.1281111  12.10625231 12.09514108 11.79433792\n 12.05815252 11.48246626 11.87687389 11.57590026 12.17818744 11.60367983\n 12.04060821 12.18841771 11.9511804  12.42250573 11.56171563 12.7512997\n 12.47418956 11.66564655 11.69940503 12.56024446 11.32659589 11.6784399\n 11.65268741 11.8493977  11.94470788 12.13269518 12.31043266 11.81303006\n 11.8493977  12.10071213 12.2067774  11.98292909 12.14153412 11.90496755\n 12.88520203 11.71177632 11.74403719 12.27839331 11.83500896 11.76756768\n 11.33260191 11.9511804  12.34583459 11.57355009 12.29910751 11.96400108\n 12.4292162  11.94470788 12.05980333 12.09514108 11.81303006 12.72783821\n 12.25486281 11.8968264  12.04355372 11.90496755 12.27373129 11.76368418\n 11.86709728 12.22096126 11.8277362  12.07539432 12.49312952 12.32341114\n 11.90496755 11.70849225 12.05233855 12.92999148 11.54248427 12.01364014\n 12.79917571 11.8493977  11.75978554 12.17561344 11.6307085  11.57119437\n 12.10348606 12.53357621 11.99535161 11.98915964 11.91371298 12.36734079\n 11.49882654 11.96356787 11.87027118 12.49874226 12.35449265 12.30817787\n 11.6127708  12.54075757 12.14685329 12.52452638 11.73606902 11.8493977\n 12.15477935 11.8493977  12.69250311 11.49577931 12.21503239 11.92503512\n 12.84397135 11.58988651 11.82407989 12.33655251 11.7905572  12.56374709\n 12.01370075 12.18586994 12.01309451 12.16525065 12.43320822 11.89818787\n 12.49117264 12.06104687 11.84510278 10.86856845 11.60823564 12.13725833\n 12.21106019 11.88448902 11.73606902 12.16525065 12.33569641 12.88567095\n 12.49125159 13.19561384 11.51292546 12.32829028 12.20856953 11.6784399\n 11.98292909 12.01066585 11.68687877 11.86709728 12.02574909 11.51292546\n 12.53537639 12.08069081 11.81303006 11.65268741 12.15451616 12.06681058].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as n\n",
    "from LinearRegression import LinearRegression\n",
    "train_data = pd.read_csv(\"csv/train.csv\") \n",
    "test_data = pd.read_csv(\"csv/test.csv\")\n",
    "\n",
    "lr = LinearRegression(train_data[['SalePrice','MSSubClass']])\n",
    "# Dealing with null value\n",
    "lr.dealingNullValue()\n",
    "# Lebel the data and target\n",
    "x,y = lr. labelData()\n",
    "# split data into training and test datasets\n",
    "x_train, x_test, y_train, y_test=lr.splitData(x,y)\n",
    "# Fit the model\n",
    "model = lr.fitModel(x_train,y_train)\n",
    "# Calculate R2 score\n",
    "print(\"R^2 is: \\n\", model.score(x_test, y_test))\n",
    "# predict the model\n",
    "prediction = lr.predict(model,x_test,y_test)\n",
    "# Mean Square Error\n",
    "lr.meanSquareError(y_test, prediction)\n",
    "# show Graph\n",
    "lr.showGraph(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Put all the data into our sets\n",
    "lr = LinearRegression(train_data)\n",
    "lr.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's remove the unrelated features\n",
    "# Correlating with salePrice\n",
    "Correlation = train_data.corr()\n",
    "Correlation['SalePrice'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting highly correlated features\n",
    "cor_target = Correlation['SalePrice']\n",
    "relevant_features = cor_target[cor_target>0.02]\n",
    "Index=relevant_features.keys()\n",
    "print(Index)\n",
    "print(\"Total index:\",len(Index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_data=pd.DataFrame(train_data,columns=Index)\n",
    "print(relevant_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Put all the data into our sets\n",
    "lr = LinearRegression(relevant_data)\n",
    "lr.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about non numeric data ??\n",
    "\n",
    "print (\"Original: \\n\")\n",
    "print (train_data.Street.value_counts(), \"\\n\")\n",
    "\n",
    "# our model needs numerical data, so we will use one-hot encoding to transform the data into a Boolean column.\n",
    "# create a new column called enc_street. The pd.get_dummies() method will handle this for us\n",
    "# Get Dummy Convert categorical variable into dummy/indicator variables\n",
    "train_data['enc_street'] = pd.get_dummies(train_data.Street, drop_first=True)\n",
    "test_data['enc_street'] = pd.get_dummies(test_data.Street, drop_first=True)\n",
    "\n",
    "print ('Encoded: \\n')\n",
    "print (train_data.enc_street.value_counts())  # Pave and Grvl values converted into 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at SaleCondition by constructing and plotting a pivot table, as we did above for OverallQual\n",
    "condition_pivot = train_data.pivot_table(index='SaleCondition', values='SalePrice', aggfunc=np.median)\n",
    "condition_pivot.plot(kind='bar', color='blue')\n",
    "plt.xlabel('Sale Condition')\n",
    "plt.ylabel('Median Sale Price')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode this SaleCondition as a new feature by using a similar method that we used for Street above\n",
    "def encode(x): return 1 if x == 'Partial' else 0\n",
    "train_data['enc_condition'] = train_data.SaleCondition.apply(encode)\n",
    "test_data['enc_condition'] = test_data.SaleCondition.apply(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore this newly modified feature as a plot.\n",
    "condition_pivot = train_data.pivot_table(index='enc_condition', values='SalePrice', aggfunc=np.median)\n",
    "condition_pivot.plot(kind='bar', color='g')\n",
    "plt.xlabel('Encoded Sale Condition')\n",
    "plt.ylabel('Median Sale Price')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Put all the data into our sets\n",
    "lr = LinearRegression(train_data)\n",
    "lr.filterCorrelated('SalePrice',0.01)\n",
    "lr.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the features from the test data for the model as we did above.\n",
    "feats = test_data.select_dtypes(\n",
    "    include=[np.number]).drop(['Id'], axis=1).interpolate()\n",
    "\n",
    "# generate predictions\n",
    "predictions = model.predict(feats)\n",
    "\n",
    "# transform the predictions to the correct form\n",
    "# apply np.exp() to our predictions becasuse we have taken the logarithm(np.log()) previously.\n",
    "final_predictions = np.exp(predictions)\n",
    "print(final_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
